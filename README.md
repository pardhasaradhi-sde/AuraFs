<p align="center">
  <h1 align="center">ğŸ§  AuraFS â€” Semantic Entropy File System</h1>
  <p align="center">
    <strong>AI-Powered Intelligent File Organization</strong><br/>
    <em>Drop files. Watch them organize themselves.</em>
  </p>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white" alt="Python 3.10+" />
  <img src="https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=white" alt="React 18" />
  <img src="https://img.shields.io/badge/FastAPI-0.100+-009688?logo=fastapi&logoColor=white" alt="FastAPI" />
  <img src="https://img.shields.io/badge/Vite-6-646CFF?logo=vite&logoColor=white" alt="Vite 6" />
  <img src="https://img.shields.io/badge/License-MIT-green" alt="MIT License" />
</p>

---

## ğŸ“– Table of Contents

1. [What is AuraFS?](#-what-is-aurafs)
2. [Key Features](#-key-features)
3. [System Architecture](#-system-architecture)
4. [Pipeline Flow](#-pipeline-flow)
5. [Technology Stack](#-technology-stack)
6. [Project Structure](#-project-structure)
7. [Module Deep Dive](#-module-deep-dive)
8. [Getting Started](#-getting-started)
9. [API Reference](#-api-reference)
10. [How It Works â€” Under the Hood](#-how-it-works--under-the-hood)
11. [Error Handling & Resilience](#-error-handling--resilience)
12. [Hackathon Details](#-hackathon-details)

---

## ğŸ§  What is AuraFS?

AuraFS (formerly SEFS â€” **S**emantic **E**ntropy **F**ile **S**ystem) is an **AI-powered file organization system** that automatically reads, understands, and sorts your documents into semantically meaningful folders â€” **in real time**.

Instead of manually creating folders and dragging files around, you simply **drop files into a watched directory** and AuraFS:

1. **Detects** the file via real-time OS-level monitoring
2. **Extracts** text content (PDF or TXT) with auto-encoding detection
3. **Embeds** the text into a 384-dimensional semantic vector using a neural network
4. **Classifies** files using a hybrid keyword + KMeans clustering approach
5. **Names** each cluster intelligently using LLM (Groq Llama 3.3 70B) with fallbacks
6. **Organizes** your OS folders automatically to match the semantic structure
7. **Broadcasts** every step live to a React dashboard via WebSocket

> **ğŸ’¡ Why is this different?**
> AuraFS goes beyond keyword matching â€” it understands *meaning*. A file about "revenue forecasting" and another about "quarterly earnings" will be grouped together even though they share no keywords, because their *semantic embeddings* are close in vector space. The hybrid approach then ensures that domain-specific files (legal contracts, financial reports) land in precisely named categories.

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ”’ **Privacy-First** | Embeddings run 100% locally using `all-MiniLM-L6-v2` â€” your files never leave your machine |
| âš¡ **Real-Time** | Watchdog monitors your folder. New file? Organized in seconds. |
| ğŸ¯ **Hybrid Clustering** | Keyword-first classification (30+ categories) â†’ KMeans for uncategorized files |
| ğŸ¤– **LLM Naming** | Groq Llama 3.3 70B generates human-readable cluster names, with TF-IDF fallback |
| ğŸ“Š **Live Dashboard** | React + react-force-graph-2d visualization with interactive clusters |
| ğŸ“ **OS Folder Sync** | Creates real `SEFS_*` folders on your filesystem â€” no virtual abstractions |
| ğŸ”„ **WebSocket Streaming** | Every pipeline step broadcasts live to the frontend |
| ğŸ“¤ **Drag & Drop Upload** | Upload files directly through the web UI |
| ğŸ›¡ï¸ **Resilient Pipeline** | Graceful fallbacks at every stage â€” never crashes |

---

## ğŸ— System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Landing Page â”‚  â”‚  Dashboard   â”‚  â”‚   2D Force Graph      â”‚  â”‚
â”‚  â”‚ (LandingPage â”‚  â”‚ (Dashboard   â”‚  â”‚   (Graph2D.jsx)       â”‚  â”‚
â”‚  â”‚    .jsx)     â”‚  â”‚    .jsx)     â”‚  â”‚  â€¢ Cluster clouds     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â€¢ File nodes         â”‚  â”‚
â”‚                           â”‚          â”‚  â€¢ Hover tooltips      â”‚  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â€¢ Click to open      â”‚  â”‚
â”‚                    â”‚ useWebSocket â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    â”‚    .js       â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                           â”‚ WebSocket                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                           â”‚                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”       BACKEND (FastAPI)     â”‚
â”‚                    â”‚   main.py    â”‚                              â”‚
â”‚                    â”‚ Orchestrator â”‚                              â”‚
â”‚                    â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”˜                              â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚           â”‚       â”‚     â”‚  â”‚     â”‚        â”‚                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”â”‚  â”‚â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”              â”‚
â”‚     â”‚watcher â”‚ â”‚extracâ”‚â”‚  â”‚â”‚embedderâ”‚â”‚clustererâ”‚              â”‚
â”‚     â”‚  .py   â”‚ â”‚tor.pyâ”‚â”‚  â”‚â”‚  .py   â”‚â”‚  .py    â”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚          â”‚              â”‚  â”‚               â”‚                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”              â”‚
â”‚     â”‚watched_ â”‚   â”‚state.pyâ”‚        â”‚organiser  â”‚              â”‚
â”‚     â”‚folder/  â”‚   â”‚        â”‚        â”‚  .py      â”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                           â”‚                    â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                                    â”‚ SEFS_*      â”‚              â”‚
â”‚                                    â”‚ Folders     â”‚              â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     EXTERNAL SERVICES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Sentence-Transformersâ”‚  â”‚ Groq API (Llama 3.3 70B)    â”‚     â”‚
â”‚  â”‚ all-MiniLM-L6-v2     â”‚  â”‚ Cluster naming (with        â”‚     â”‚
â”‚  â”‚ (LOCAL - 384 dims)   â”‚  â”‚ TF-IDF fallback)            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  File    â”‚     â”‚  Text    â”‚     â”‚   AI     â”‚     â”‚   Hybrid     â”‚     â”‚  Folder  â”‚     â”‚ WebSocketâ”‚
 â”‚ Dropped  â”‚â”€â”€â”€â”€â–¶â”‚Extracted â”‚â”€â”€â”€â”€â–¶â”‚Embedding â”‚â”€â”€â”€â”€â–¶â”‚  Clustering  â”‚â”€â”€â”€â”€â–¶â”‚  Sync    â”‚â”€â”€â”€â”€â–¶â”‚Broadcast â”‚
 â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚              â”‚     â”‚          â”‚     â”‚          â”‚
 â”‚ watcher  â”‚     â”‚extractor â”‚     â”‚ embedder â”‚     â”‚ keyword-firstâ”‚     â”‚organiser â”‚     â”‚ main.py  â”‚
 â”‚   .py    â”‚     â”‚  .py     â”‚     â”‚   .py    â”‚     â”‚ + KMeans     â”‚     â”‚  .py     â”‚     â”‚          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    3s debounce    PDF: 10 pages    384-dim vector    30+ categories      Creates SEFS_*    Real-time
                   TXT: auto-enc    Chunked avg       + silhouette       Move files        graph update
```

---

## ğŸ”„ Pipeline Flow

### Step-by-Step Processing

```
1. FILE DETECTION
   â””â”€ Watchdog observer monitors root/ (recursive)
   â””â”€ Debounces rapid events (3s window)
   â””â”€ Ignores: SEFS_* folders, hidden files, .staging/, unsupported types
   â””â”€ Supported: .pdf, .txt

2. TEXT EXTRACTION (extractor.py)
   â””â”€ PDF â†’ PyMuPDF (first 10 pages, whitespace cleaned)
   â””â”€ TXT â†’ chardet auto-encoding detection (UTF-8, Latin-1, etc.)
   â””â”€ Returns clean text string (empty string on failure)

3. SEMANTIC EMBEDDING (embedder.py)
   â””â”€ Model: all-MiniLM-L6-v2 (22M params, runs locally)
   â””â”€ Short text (â‰¤500 chars) â†’ embed directly
   â””â”€ Long text â†’ chunk at sentence boundaries (500 chars/chunk, max 20)
      â””â”€ Batch embed all chunks
      â””â”€ Weighted average (earlier chunks = higher weight)
      â””â”€ L2 normalize to unit vector
   â””â”€ Output: 384-dimensional numpy vector

4. HYBRID CLUSTERING (main.py â†’ clusterer.py)
   â”Œâ”€ PHASE A: Keyword-First Classification
   â”‚  â””â”€ For each file: scan text + filename against CATEGORY_MAP
   â”‚  â””â”€ 30+ categories (Financial, Legal, AI Research, Biology, etc.)
   â”‚  â””â”€ Word-boundary regex matching with scoring
   â”‚  â””â”€ Filename matches weighted 3x (filename is strong signal)
   â”‚  â””â”€ Threshold: â‰¥1 keyword match AND score â‰¥2
   â”‚  â””â”€ Group files by detected category
   â”‚
   â”œâ”€ PHASE B: KMeans for Uncategorized
   â”‚  â””â”€ Files with no keyword match â†’ KMeans clustering
   â”‚  â””â”€ Optimal K via silhouette score (K=2 to K=8)
   â”‚  â””â”€ Name clusters via Groq LLM or TF-IDF fallback
   â”‚
   â””â”€ PHASE C: De-duplication & Merge
      â””â”€ Merge clusters with identical names
      â””â”€ Build final assignments map

5. 3D POSITIONING (clusterer.py)
   â””â”€ n < 15 files â†’ PCA projection to 3D
   â””â”€ n â‰¥ 15 files â†’ UMAP projection to 3D
   â””â”€ Normalize coordinates to [-5, 5] range
   â””â”€ Used for x/y positions in 2D graph visualization

6. FOLDER SYNCHRONIZATION (organiser.py)
   â””â”€ Create SEFS_<ClusterName>/ folders
   â””â”€ Move files into assigned folders
   â””â”€ Handle naming conflicts (_1, _2 suffixes)
   â””â”€ Clean up empty SEFS_* folders
   â””â”€ Pre-mark moved paths so watcher ignores them (15s TTL)

7. BROADCAST (main.py)
   â””â”€ Serialize graph state (files, clusters, positions)
   â””â”€ WebSocket â†’ all connected frontend clients
   â””â”€ Activity log entry â†’ real-time event stream
```

---

## ğŸ›  Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Backend Framework** | FastAPI + Uvicorn | Async REST API + WebSocket server |
| **File Watching** | Watchdog | OS-level file system event monitoring |
| **Text Extraction** | PyMuPDF (fitz) | PDF text extraction (up to 10 pages) |
| **Encoding Detection** | chardet | Auto-detect TXT file encodings |
| **AI Embeddings** | Sentence-Transformers (`all-MiniLM-L6-v2`) | Convert text â†’ 384-dim vectors (LOCAL) |
| **Clustering** | scikit-learn (KMeans) | Group similar embeddings |
| **Cluster Evaluation** | scikit-learn (Silhouette Score) | Find optimal cluster count |
| **Dimensionality Reduction** | PCA / UMAP | Project 384-dim â†’ 3D for visualization |
| **LLM Naming** | Groq API (Llama 3.3 70B Versatile) | Content-aware cluster names |
| **Fallback Naming** | TF-IDF (scikit-learn) | Keyword extraction when LLM unavailable |
| **Frontend** | React 18 + Vite 6 | Reactive dashboard UI |
| **Visualization** | react-force-graph-2d | Interactive 2D cluster graph |
| **Styling** | Tailwind CSS 3 | Utility-first styling |
| **Real-time Comms** | WebSocket (native) | Live activity log + state updates |
| **Routing** | react-router-dom v7 | SPA navigation |
| **Icons** | Lucide React + Material Symbols | UI iconography |

---

## ğŸ“ Project Structure

```
sefs/
â”œâ”€â”€ README.md                    â† You are here
â”œâ”€â”€ ARCHITECTURE.md              â† Detailed system documentation
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  â† FastAPI server + pipeline orchestrator (671 lines)
â”‚   â”‚                               â€¢ REST endpoints (/graph, /upload, /open, /health)
â”‚   â”‚                               â€¢ WebSocket broadcast system
â”‚   â”‚                               â€¢ Hybrid _recluster_all() algorithm
â”‚   â”‚                               â€¢ Startup file scanner
â”‚   â”‚
â”‚   â”œâ”€â”€ extractor.py             â† PDF/TXT text extraction (58 lines)
â”‚   â”‚                               â€¢ PyMuPDF for PDFs (10-page cap)
â”‚   â”‚                               â€¢ chardet auto-encoding for TXT
â”‚   â”‚
â”‚   â”œâ”€â”€ embedder.py              â† Chunked AI embedding (98 lines)
â”‚   â”‚                               â€¢ all-MiniLM-L6-v2 (384-dim output)
â”‚   â”‚                               â€¢ Sentence-boundary chunking
â”‚   â”‚                               â€¢ Weighted average with L2 normalization
â”‚   â”‚
â”‚   â”œâ”€â”€ clusterer.py             â† Clustering + naming engine (725 lines)
â”‚   â”‚                               â€¢ CATEGORY_MAP (30+ categories, 500+ keywords)
â”‚   â”‚                               â€¢ KMeans with silhouette optimization
â”‚   â”‚                               â€¢ Groq LLM naming â†’ TF-IDF fallback
â”‚   â”‚                               â€¢ PCA/UMAP 3D projection
â”‚   â”‚
â”‚   â”œâ”€â”€ watcher.py               â† File system monitor (110 lines)
â”‚   â”‚                               â€¢ Watchdog observer with 3s debounce
â”‚   â”‚                               â€¢ SEFS_* folder ignore filter
â”‚   â”‚
â”‚   â”œâ”€â”€ organiser.py             â† OS folder synchronization (131 lines)
â”‚   â”‚                               â€¢ Create/sync SEFS_* folders
â”‚   â”‚                               â€¢ File moves with conflict resolution
â”‚   â”‚                               â€¢ Empty folder cleanup
â”‚   â”‚
â”‚   â”œâ”€â”€ state.py                 â† Global in-memory state (49 lines)
â”‚   â”‚                               â€¢ files dict, clusters dict
â”‚   â”‚                               â€¢ Activity log (deque, max 50 entries)
â”‚   â”‚                               â€¢ Cluster color palette (8 colors)
â”‚   â”‚
â”‚   â”œâ”€â”€ generate_test_data.py    â† Test data generator (70 lines)
â”‚   â”‚                               â€¢ Creates 11 sample files (physics + biology)
â”‚   â”‚
â”‚   â””â”€â”€ requirements.txt        â† Python dependencies (11 packages)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json             â† Frontend dependencies
â”‚   â”œâ”€â”€ vite.config.js           â† Vite build configuration
â”‚   â”œâ”€â”€ tailwind.config.js       â† Tailwind CSS config
â”‚   â”œâ”€â”€ postcss.config.js        â† PostCSS config
â”‚   â”œâ”€â”€ index.html               â† HTML entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ public/                  â† Static assets
â”‚   â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.jsx             â† React entry point + BrowserRouter
â”‚       â”œâ”€â”€ App.jsx              â† Route definitions (/ â†’ Landing, /dashboard â†’ Dashboard)
â”‚       â”œâ”€â”€ App.css              â† Global styles + dark theme
â”‚       â”œâ”€â”€ index.css            â† Tailwind directives
â”‚       â”œâ”€â”€ Landing.css          â† Landing page styles
â”‚       â”‚
â”‚       â”œâ”€â”€ LandingPage.jsx      â† Landing page (292 lines)
â”‚       â”‚                           â€¢ Hero section, feature grid
â”‚       â”‚                           â€¢ Workflow visualization
â”‚       â”‚                           â€¢ CTA buttons
â”‚       â”‚
â”‚       â”œâ”€â”€ Dashboard.jsx        â† Main dashboard (373 lines)
â”‚       â”‚                           â€¢ Stats cards (files, clusters, words)
â”‚       â”‚                           â€¢ Pipeline visualization banner
â”‚       â”‚                           â€¢ File upload (drag & drop + click)
â”‚       â”‚                           â€¢ Cluster cards with file lists
â”‚       â”‚                           â€¢ Activity log (real-time)
â”‚       â”‚                           â€¢ Graph overlay toggle
â”‚       â”‚
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ Graph2D.jsx      â† 2D force graph (367 lines)
â”‚       â”‚   â”‚                       â€¢ Cluster glow backgrounds
â”‚       â”‚   â”‚                       â€¢ File node rendering
â”‚       â”‚   â”‚                       â€¢ Hover tooltips with metadata
â”‚       â”‚   â”‚                       â€¢ Click-to-open file
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ Graph3D.jsx      â† 3D graph (optional)
â”‚       â”‚
â”‚       â””â”€â”€ hooks/
â”‚           â””â”€â”€ useWebSocket.js  â† WebSocket hook (113 lines)
â”‚                                   â€¢ Auto-reconnect with exponential backoff
â”‚                                   â€¢ State management for graph + logs
â”‚
â””â”€â”€ root/                        â† Drop files here!
    â”œâ”€â”€ SEFS_Biology Research/   â† Auto-created by AuraFS
    â”œâ”€â”€ SEFS_Physics Research/   â† Auto-created by AuraFS
    â””â”€â”€ ...
```

---

## ğŸ”¬ Module Deep Dive

### Backend Pipeline â€” `main.py`

The central orchestrator that wires all modules together:

| Component | Description |
|-----------|-------------|
| `pipeline_lock` | Threading lock preventing concurrent pipeline runs |
| `ignore_paths` | Dict of paths to ignore (TTL=15s) to prevent watcher re-triggers |
| `_RECLUSTER_DELAY` | 5s debounce before re-clustering (batches rapid file drops) |
| `_startup_done` | Flag to distinguish startup scan from live file events |

**Key Functions:**

- **`process_pipeline(event, path)`** â€” Entry point from watcher. Routes created/modified/deleted events.
- **`_ingest_one(path)`** â€” Extract â†’ Embed â†’ Store a single file.
- **`_do_recluster()`** â€” Debounced recluster trigger. Waits 5s after last file event.
- **`_recluster_all()`** â€” The brain: hybrid keyword-first + KMeans clustering.
- **`get_graph_state()`** â€” Serializes state to JSON for frontend (files + clusters + positions).
- **`_process_existing_files()`** â€” Startup scanner: ingests all existing files, clusters once.

**Threading Model:**
```
Main Thread (asyncio)      â†’  FastAPI + WebSocket handling
Background Thread 1        â†’  _process_existing_files() on startup
Background Thread 2        â†’  Watchdog Observer (file monitoring)
Timer Threads (per-file)   â†’  Debounce timers from watcher
Timer Thread               â†’  Recluster delay (5s batch window)
```

### Hybrid Clustering Algorithm

The core innovation â€” a two-phase approach that combines **domain knowledge** with **unsupervised learning**:

```
Input: N files with embeddings + extracted text

Phase 1 â€” Keyword Classification (Deterministic)
  For each file:
    1. Tokenize text into words
    2. Match against CATEGORY_MAP (30+ categories, 500+ keywords)
    3. Score = Î£(word-boundary matches) + 3Ã— filename matches
    4. If score â‰¥ 2 AND match_count â‰¥ 1 â†’ assign to category
    5. Group all files with same category into one cluster

Phase 2 â€” KMeans Fallback (Unsupervised)
  For uncategorized files (no keyword matches):
    1. Extract their embeddings (384-dim vectors)
    2. If only 1-2 files â†’ assign to "General Documents"
    3. If 3+ files â†’ KMeans with silhouette optimization
       - Try K = 2 to min(8, n-1)
       - Pick K with highest silhouette score
       - Name via Groq LLM or TF-IDF
    4. Assign cluster IDs

Phase 3 â€” Merge & Deduplicate
  - If KMeans produces a name matching an existing category â†’ merge
  - Reassign cluster IDs for clean sequential numbering
```

**Why hybrid?** Pure KMeans lumps dissimilar files together when file count is low. Pure keyword matching misses novel topics. The hybrid approach gets the best of both â€” precise categorization for known domains, intelligent grouping for unknown ones.

### Embedding Strategy â€” `embedder.py`

```
Input Text â†’ Length Check
  â”‚
  â”œâ”€ Short (â‰¤500 chars) â†’ Direct embedding â†’ 384-dim vector
  â”‚
  â””â”€ Long (>500 chars) â†’ Chunk at sentence boundaries
                           â”‚
                           â”œâ”€ Chunk 0: weight 1.00 (most important)
                           â”œâ”€ Chunk 1: weight 0.91
                           â”œâ”€ Chunk 5: weight 0.67
                           â”œâ”€ ...
                           â””â”€ Chunk 19: weight 0.33 (least important)
                           â”‚
                           â””â”€ Weighted average â†’ L2 normalize â†’ 384-dim vector
```

**Why weighted?** Introductions and abstracts contain the strongest topic signals. The decay formula `1/(1 + 0.1i)` gives early chunks ~3Ã— the influence of late chunks.

### CATEGORY_MAP â€” `clusterer.py`

30+ domain categories with 500+ keywords enabling precise classification:

| Category | Example Keywords |
|----------|-----------------|
| Financial Documents | revenue, profit, balance sheet, audit, payroll |
| Legal Documents | contract, compliance, litigation, patent, NDA |
| AI Research | neural network, transformer, deep learning, LLM |
| Biology Research | DNA, gene, CRISPR, mitosis, ecology |
| Physics Research | quantum, thermodynamics, relativity, photon |
| Medical Records | patient, diagnosis, prescription, surgery |
| Startup Documents | pitch, venture, funding, burn rate, MVP |
| Software Engineering | API, framework, devops, docker, microservices |
| *...and 22 more* | |

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Node.js 18+** & npm
- **Groq API Key** (optional â€” system works without it using TF-IDF fallback)

### 1. Clone & Install Backend

```bash
cd sefs/backend
pip install -r requirements.txt
```

**Dependencies installed:**
```
fastapi           â€” Web framework with WebSocket support
uvicorn           â€” ASGI server
watchdog          â€” File system monitoring
pymupdf           â€” PDF text extraction
chardet           â€” Encoding detection
sentence-transformers â€” Local AI embeddings (downloads ~90MB model on first run)
scikit-learn      â€” KMeans, TF-IDF, Silhouette Score
umap-learn        â€” UMAP dimensionality reduction
numpy             â€” Vector operations
groq              â€” Groq Cloud API client
python-multipart  â€” File upload support
```

### 2. Install Frontend

```bash
cd sefs/frontend
npm install
```

### 3. Set Environment Variables (Optional)

```bash
# For LLM-powered cluster naming (optional)
set GROQ_API_KEY=gsk_your_key_here
```

> Without a Groq API key, AuraFS falls back to TF-IDF keyword extraction for naming clusters. The system works perfectly â€” names are just slightly less polished.

### 4. Start Backend

```bash
cd sefs/backend
python main.py
```

Server starts on **http://localhost:8000**

### 5. Start Frontend

```bash
cd sefs/frontend
npm run dev
```

Dev server starts on **http://localhost:5173**

### 6. Use It!

1. Open **http://localhost:5173** in your browser
2. Click **LAUNCH DASHBOARD**
3. Drop `.pdf` or `.txt` files into the `root/` directory (or drag into the web UI)
4. Watch the dashboard update in real-time as files are analyzed and organized!

### Generate Test Data

```bash
cd sefs/backend
python generate_test_data.py
```

Creates 11 sample files (6 physics + 5 biology) to demonstrate clustering.

---

## ğŸ“¡ API Reference

### WebSocket `/ws`

Real-time bidirectional communication.

**On connect, server sends:**
```json
{
  "type": "graph_update",
  "nodes": [...],
  "files": [...],
  "clusters": [...],
  "clusters_map": { "0": {...}, "1": {...} },
  "total_files": 7
}
```
```json
{
  "type": "activity_log",
  "logs": [{ "timestamp": 1707..., "time_str": "21:15:03", "type": "cluster", "message": "...", "icon": "ğŸ“" }]
}
```

**Incremental updates:**
```json
{ "type": "activity_log_entry", "entry": { ... } }
```

### REST Endpoints

| Endpoint | Method | Description | Response |
|----------|--------|-------------|----------|
| `/ws` | WebSocket | Real-time state + log streaming | Bidirectional |
| `/graph` | GET | Current graph state | `{ nodes, files, clusters, clusters_map, total_files }` |
| `/health` | GET | Health check | `{ status, files, clusters }` |
| `/logs` | GET | Recent activity log | `{ logs: [...] }` |
| `/open?path=...` | GET | Open file in OS default app | `{ status: "opened" }` |
| `/upload` | POST | Upload files (multipart) | `{ status, uploaded, count }` |

### File Node Schema

```json
{
  "id": "D:\\path\\to\\file.pdf",
  "path": "D:\\path\\to\\file.pdf",
  "name": "file.pdf",
  "snippet": "First 200 chars of content...",
  "word_count": 1523,
  "cluster_id": 0,
  "cluster_name": "AI Research",
  "color": "#6366f1",
  "keywords": ["neural", "learning", "model", "training", "network"],
  "x": 1.23,
  "y": -3.45,
  "position": [1.23, -3.45, 5.67]
}
```

### Cluster Schema

```json
{
  "id": 0,
  "name": "AI Research",
  "color": "#6366f1",
  "file_count": 4
}
```

---

## âš™ How It Works â€” Under the Hood

### Token Limit Management

Large files can contain 50,000+ characters. AuraFS handles this through three layers:

| Layer | Module | Strategy | Limit |
|-------|--------|----------|-------|
| **Extraction** | `extractor.py` | PDFs capped at 10 pages | ~5,000 words |
| **Embedding** | `embedder.py` | Chunked: 500-char chunks, batch embed, weighted avg | 20 chunks = 10,000 chars |
| **LLM Naming** | `clusterer.py` | `_smart_truncate()`: 60% start + 40% end, 300 chars/file | ~7,200 chars total |

### Watcher Anti-Loop Design

When AuraFS moves a file into `SEFS_Finance/`, the watcher would detect this as a new "create" event, triggering an infinite loop. Three mechanisms prevent this:

1. **`_should_ignore()`** â€” Filters out ALL events inside `SEFS_*` directories
2. **`ignore_paths`** â€” Pre-marks destination paths before moves (15s TTL)
3. **`_premark_moves()`** â€” Registers expected move destinations before they happen

### WebSocket Architecture

```
Backend (Python)                    Frontend (React)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ main.py     â”‚   WebSocket        â”‚ useWebSocket.js  â”‚
â”‚             â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                  â”‚
â”‚ broadcast() â”‚   JSON messages    â”‚ â€¢ graphData      â”‚
â”‚             â”‚                    â”‚ â€¢ logs           â”‚
â”‚ Async event â”‚                    â”‚ â€¢ connected      â”‚
â”‚ loop        â”‚                    â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚ Auto-reconnect   â”‚
                                   â”‚ (exp. backoff)   â”‚
                                   â”‚ 2sâ†’4sâ†’8sâ†’16sâ†’30sâ”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Graph Visualization â€” `Graph2D.jsx`

The 2D force graph renders three layers using canvas:

1. **Cluster Clouds** â€” Radial gradient backgrounds centered on cluster centroid, sized by member count
2. **Links** â€” Semi-transparent lines connecting files to their cluster center
3. **File Nodes** â€” Colored circles with filename labels

**Interaction:**
- **Hover** â†’ Tooltip with filename, cluster, word count, keywords, snippet
- **Click file** â†’ Opens file via backend `/open` endpoint
- **Click cluster** â†’ Zooms to fit that cluster
- **Scroll** â†’ Zoom in/out
- **Drag** â†’ Pan the canvas

---

## ğŸ›¡ Error Handling & Resilience

| Scenario | How AuraFS Handles It |
|----------|----------------------|
| PDF extraction fails | Returns empty string, logs warning, skips file |
| Encoding detection fails | Falls back to UTF-8 with error replacement |
| Groq API down | Falls back to TF-IDF keyword extraction for naming |
| Groq rate limited | Falls back to TF-IDF (no crash) |
| File moved by organiser triggers watcher | `_should_ignore()` + `ignore_paths` prevents re-trigger |
| Rapid file saves | 3s debounce in watcher prevents duplicate processing |
| Many files dropped at once | 5s recluster delay batches all into one clustering pass |
| Concurrent pipeline calls | `pipeline_lock` serializes all processing |
| WebSocket client disconnects | Removed from pool, no error |
| WebSocket send fails | Client marked dead, removed from pool |
| File naming conflicts | Appends `_1`, `_2`, etc. |
| Empty text extracted | Logs warning, skips file |
| numpy types in JSON | `default=str` serializer handles all edge cases |

---

## ğŸ† Hackathon Details

### Problem Statement

**Intelligent File Organization Using AI** â€” Build a system that automatically understands and organizes files based on their semantic content, eliminating the need for manual folder management.

### Our Solution

AuraFS is a **real-time, AI-powered semantic file organizer** that combines:

- **Local AI** (all-MiniLM-L6-v2) for privacy-preserving document understanding
- **Hybrid clustering** (keyword-first + KMeans) for accurate categorization
- **LLM naming** (Groq Llama 3.3 70B) for human-readable folder names
- **Live visualization** (React + force-directed graphs) for intuitive monitoring
- **OS-level integration** (actual folder creation + file moves) for tangible results

### What Makes AuraFS Unique

1. **Hybrid Approach** â€” No other solution combines deterministic keyword classification with unsupervised ML clustering. This achieves both precision (for known domains) and flexibility (for novel topics).

2. **Privacy-First** â€” Embeddings run 100% locally. Only cluster naming (optionally) uses a cloud API, and even that has a fully offline TF-IDF fallback.

3. **Real, Not Virtual** â€” AuraFS creates actual OS folders. Close the app, and your files are still organized. This isn't a virtual overlay â€” it's a permanent improvement.

4. **Live Pipeline Visualization** â€” Every step of the AI pipeline is visible in real-time through WebSocket streaming and an interactive force-directed graph.

### Team

**It Works On My Machine**

### TeamLead

**Pardha Saradhi(Pardhu)**

### Tech Stack Summary

```
Backend:   Python 3.10+ | FastAPI | Sentence-Transformers | KMeans | Groq
Frontend:  React 18 | Vite 6 | Tailwind CSS | react-force-graph-2d
ML:        all-MiniLM-L6-v2 (local) | KMeans + Silhouette | PCA/UMAP
Comms:     WebSocket (real-time) | REST API
```

---

<p align="center">
  <strong>AuraFS</strong> â€” Let your files organize themselves. ğŸ§ ğŸ“
</p>
